{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde30f52",
   "metadata": {},
   "source": [
    "### Setting up a quick and dirty simple autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6851c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osc16\\miniconda3\\envs\\d2d\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8908012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoEncoder import MarketAutoencoder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890e850",
   "metadata": {},
   "source": [
    "### Try Training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef151fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "import pickle\n",
    "with open(\"1.6kRunDemo.pkl\",\"rb\") as fp:\n",
    "    paths = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558fae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1, Batch 1000 loss: 0.43646489664428245\n",
      "Epoch1, Batch 3000 loss: 0.02615692541221935\n",
      "Epoch1, Batch 5000 loss: 0.02573225842581218\n",
      "Epoch1, Batch 7000 loss: 0.025481427626339023\n",
      "Epoch2, Batch 1000 loss: 0.029583406717520286\n",
      "Epoch2, Batch 3000 loss: 0.02502911913424392\n",
      "Epoch2, Batch 5000 loss: 0.02480070326793023\n",
      "Epoch2, Batch 7000 loss: 0.024749569835552813\n",
      "Epoch3, Batch 1000 loss: 0.029025374579812625\n",
      "Epoch3, Batch 3000 loss: 0.024565998178689485\n",
      "Epoch3, Batch 5000 loss: 0.024472941530646122\n",
      "Epoch3, Batch 7000 loss: 0.024387568443041793\n",
      "Epoch4, Batch 1000 loss: 0.028627742407629227\n",
      "Epoch4, Batch 3000 loss: 0.0242278724147746\n",
      "Epoch4, Batch 5000 loss: 0.024163253741676074\n",
      "Epoch4, Batch 7000 loss: 0.02418276365141656\n",
      "Epoch5, Batch 1000 loss: 0.028395280779416977\n",
      "Epoch5, Batch 3000 loss: 0.023975891152231157\n",
      "Epoch5, Batch 5000 loss: 0.02396302072005053\n",
      "Epoch5, Batch 7000 loss: 0.023870536353556127\n",
      "Epoch6, Batch 1000 loss: 0.02298555027290487\n",
      "Epoch6, Batch 3000 loss: 0.014144673002436728\n",
      "Epoch6, Batch 5000 loss: 0.014133213083952137\n",
      "Epoch6, Batch 7000 loss: 0.013943047935668655\n",
      "Epoch7, Batch 1000 loss: 0.01622437920384696\n",
      "Epoch7, Batch 3000 loss: 0.009968849056535202\n",
      "Epoch7, Batch 5000 loss: 0.009046584016037707\n",
      "Epoch7, Batch 7000 loss: 0.007799925072771238\n",
      "Epoch8, Batch 1000 loss: 0.007627738087742726\n",
      "Epoch8, Batch 3000 loss: 0.006310770389342763\n",
      "Epoch8, Batch 5000 loss: 0.006253404788215737\n",
      "Epoch8, Batch 7000 loss: 0.006222102441572033\n",
      "Epoch9, Batch 1000 loss: 0.007240726113877289\n",
      "Epoch9, Batch 3000 loss: 0.005976621458293435\n",
      "Epoch9, Batch 5000 loss: 0.005457839552181313\n",
      "Epoch9, Batch 7000 loss: 0.005098968793976823\n",
      "Epoch10, Batch 1000 loss: 0.006123002267734238\n",
      "Epoch10, Batch 3000 loss: 0.0050152751800829395\n",
      "Epoch10, Batch 5000 loss: 0.004895095408809087\n",
      "Epoch10, Batch 7000 loss: 0.00485359015967616\n",
      "Epoch11, Batch 1000 loss: 0.0053836690831777275\n",
      "Epoch11, Batch 3000 loss: 0.004849484159956426\n",
      "Epoch11, Batch 5000 loss: 0.004312817478432292\n",
      "Epoch11, Batch 7000 loss: 0.006282204690946749\n",
      "Epoch12, Batch 1000 loss: 0.00500453864603552\n",
      "Epoch12, Batch 3000 loss: 0.0037195638398754183\n",
      "Epoch12, Batch 5000 loss: 0.0018166599681576979\n",
      "Epoch12, Batch 7000 loss: 0.0012305446937995361\n",
      "Epoch13, Batch 1000 loss: 0.0013511519427534039\n",
      "Epoch13, Batch 3000 loss: 0.001049027613549724\n",
      "Epoch13, Batch 5000 loss: 0.0009558953538513551\n",
      "Epoch13, Batch 7000 loss: 0.0006888072574701597\n",
      "Epoch14, Batch 1000 loss: 0.0006428534784942811\n",
      "Epoch14, Batch 3000 loss: 0.00046308401542921227\n",
      "Epoch14, Batch 5000 loss: 0.0004075277822879314\n",
      "Epoch14, Batch 7000 loss: 0.0003619049995225849\n",
      "Epoch15, Batch 1000 loss: 0.00038483268202656\n",
      "Epoch15, Batch 3000 loss: 0.00030208892151938955\n",
      "Epoch15, Batch 5000 loss: 0.00028138340306562814\n",
      "Epoch15, Batch 7000 loss: 0.0002697226966859427\n",
      "Epoch16, Batch 1000 loss: 0.00029879425465016685\n",
      "Epoch16, Batch 3000 loss: 0.00024917768328967224\n",
      "Epoch16, Batch 5000 loss: 0.00024933591089501485\n",
      "Epoch16, Batch 7000 loss: 0.00023098102966382777\n",
      "Epoch17, Batch 1000 loss: 0.000306030393267917\n",
      "Epoch17, Batch 3000 loss: 0.000221948413237518\n",
      "Epoch17, Batch 5000 loss: 0.00021863783509307955\n",
      "Epoch17, Batch 7000 loss: 0.00021478283080983543\n",
      "Epoch18, Batch 1000 loss: 0.0002473689304174312\n",
      "Epoch18, Batch 3000 loss: 0.0002064889751640194\n",
      "Epoch18, Batch 5000 loss: 0.00019995752871678903\n",
      "Epoch18, Batch 7000 loss: 0.00019989901405032632\n",
      "Epoch19, Batch 1000 loss: 0.0002553096416216682\n",
      "Epoch19, Batch 3000 loss: 0.0001861298812225789\n",
      "Epoch19, Batch 5000 loss: 0.00018507998684572343\n",
      "Epoch19, Batch 7000 loss: 0.0001828143987496396\n",
      "Epoch20, Batch 1000 loss: 0.00021281663205686803\n",
      "Epoch20, Batch 3000 loss: 0.0001783925593907934\n",
      "Epoch20, Batch 5000 loss: 0.0001789129246903111\n",
      "Epoch20, Batch 7000 loss: 0.00017399773026088037\n",
      "Epoch21, Batch 1000 loss: 0.0001973539651174389\n",
      "Epoch21, Batch 3000 loss: 0.00016807031523335904\n",
      "Epoch21, Batch 5000 loss: 0.0001654177098169528\n",
      "Epoch21, Batch 7000 loss: 0.001505821940651216\n",
      "Epoch22, Batch 1000 loss: 0.00023573485255374746\n",
      "Epoch22, Batch 3000 loss: 0.0001868752335735575\n",
      "Epoch22, Batch 5000 loss: 0.00018710723962719636\n",
      "Epoch22, Batch 7000 loss: 0.00018585844308893957\n",
      "Epoch23, Batch 1000 loss: 0.0002036973420805342\n",
      "Epoch23, Batch 3000 loss: 0.00017226623232775905\n",
      "Epoch23, Batch 5000 loss: 0.00016805875936705593\n",
      "Epoch23, Batch 7000 loss: 0.00016818358560395885\n",
      "Epoch24, Batch 1000 loss: 0.0002285197073825131\n",
      "Epoch24, Batch 3000 loss: 0.00016434977650354307\n",
      "Epoch24, Batch 5000 loss: 0.0001618680825973265\n",
      "Epoch24, Batch 7000 loss: 0.00020320574030298743\n",
      "Epoch25, Batch 1000 loss: 0.0002569375124338033\n",
      "Epoch25, Batch 3000 loss: 0.00016855710747655067\n",
      "Epoch25, Batch 5000 loss: 0.0001675061861314153\n",
      "Epoch25, Batch 7000 loss: 0.0001557342768056864\n",
      "Epoch26, Batch 1000 loss: 0.00018135749395561376\n",
      "Epoch26, Batch 3000 loss: 0.00015214070487986917\n",
      "Epoch26, Batch 5000 loss: 0.00014837326677065722\n",
      "Epoch26, Batch 7000 loss: 0.0011775306860914265\n",
      "Epoch27, Batch 1000 loss: 0.0010898965482554776\n",
      "Epoch27, Batch 3000 loss: 0.0002119102267293403\n",
      "Epoch27, Batch 5000 loss: 0.00019880333151809732\n",
      "Epoch27, Batch 7000 loss: 0.00017600572193767803\n",
      "Epoch28, Batch 1000 loss: 0.00019993302868760702\n",
      "Epoch28, Batch 3000 loss: 0.00016991039476806573\n",
      "Epoch28, Batch 5000 loss: 0.00016312329019604345\n",
      "Epoch28, Batch 7000 loss: 0.0001549541636062972\n",
      "Epoch29, Batch 1000 loss: 0.00018042261328715556\n",
      "Epoch29, Batch 3000 loss: 0.00014844366126648165\n",
      "Epoch29, Batch 5000 loss: 0.00014980902215401006\n",
      "Epoch29, Batch 7000 loss: 0.00014887856715946294\n",
      "Epoch30, Batch 1000 loss: 0.0001744676292303286\n",
      "Epoch30, Batch 3000 loss: 0.0001429959307897873\n",
      "Epoch30, Batch 5000 loss: 0.00014325630247098768\n",
      "Epoch30, Batch 7000 loss: 0.00014018483382372113\n",
      "Epoch31, Batch 1000 loss: 0.0001702536055913172\n",
      "Epoch31, Batch 3000 loss: 0.00014941014514513711\n",
      "Epoch31, Batch 5000 loss: 0.00013509099013769794\n",
      "Epoch31, Batch 7000 loss: 0.000150700337916596\n",
      "Epoch32, Batch 1000 loss: 0.0001605929348243397\n",
      "Epoch32, Batch 3000 loss: 0.00015687524031137272\n",
      "Epoch32, Batch 5000 loss: 0.00013417095710001052\n",
      "Epoch32, Batch 7000 loss: 0.0001335117108195192\n",
      "Epoch33, Batch 1000 loss: 0.00015643990405970283\n",
      "Epoch33, Batch 3000 loss: 0.00012896514831950198\n",
      "Epoch33, Batch 5000 loss: 0.00013003713177496385\n",
      "Epoch33, Batch 7000 loss: 0.00014760773423724103\n",
      "Epoch34, Batch 1000 loss: 0.00015057988507513042\n",
      "Epoch34, Batch 3000 loss: 0.00012516253628061915\n",
      "Epoch34, Batch 5000 loss: 0.00014213337822566033\n",
      "Epoch34, Batch 7000 loss: 0.00012478937433748033\n",
      "Epoch35, Batch 1000 loss: 0.00015563800977532168\n",
      "Epoch35, Batch 3000 loss: 0.0001229518278078013\n",
      "Epoch35, Batch 5000 loss: 0.000337951783248315\n",
      "Epoch35, Batch 7000 loss: 0.00013878847240135896\n",
      "Epoch36, Batch 1000 loss: 0.0001582228549457805\n",
      "Epoch36, Batch 3000 loss: 0.00012889780679190444\n",
      "Epoch36, Batch 5000 loss: 0.00012799653273860848\n",
      "Epoch36, Batch 7000 loss: 0.00012515262489972665\n",
      "Epoch37, Batch 1000 loss: 0.00014460351290574737\n",
      "Epoch37, Batch 3000 loss: 0.00012029522657898768\n",
      "Epoch37, Batch 5000 loss: 0.00013212768741714074\n",
      "Epoch37, Batch 7000 loss: 0.00013391489151556618\n",
      "Epoch38, Batch 1000 loss: 0.00013256727248777753\n",
      "Epoch38, Batch 3000 loss: 0.00011384164492927076\n",
      "Epoch38, Batch 5000 loss: 0.00011360164346658169\n",
      "Epoch38, Batch 7000 loss: 0.06300004926017487\n",
      "Epoch39, Batch 1000 loss: 0.017388346368115568\n",
      "Epoch39, Batch 3000 loss: 0.008010769077873998\n",
      "Epoch39, Batch 5000 loss: 0.006512054575287628\n",
      "Epoch39, Batch 7000 loss: 0.005342188872682264\n",
      "Epoch40, Batch 1000 loss: 0.005188095195086042\n",
      "Epoch40, Batch 3000 loss: 0.0033412704204136626\n",
      "Epoch40, Batch 5000 loss: 0.001622810825719424\n",
      "Epoch40, Batch 7000 loss: 0.0011444741036952073\n",
      "Epoch41, Batch 1000 loss: 0.01683418754997422\n",
      "Epoch41, Batch 3000 loss: 0.008945304673259147\n",
      "Epoch41, Batch 5000 loss: 0.02730032479783659\n",
      "Epoch41, Batch 7000 loss: 0.01730849068148608\n",
      "Epoch42, Batch 1000 loss: 0.014118564581066475\n",
      "Epoch42, Batch 3000 loss: 0.006302776291746984\n",
      "Epoch42, Batch 5000 loss: 0.027981741106842695\n",
      "Epoch42, Batch 7000 loss: 0.022301695216994183\n",
      "Epoch43, Batch 1000 loss: 0.020107815195339832\n",
      "Epoch43, Batch 3000 loss: 0.012453441328514394\n",
      "Epoch43, Batch 5000 loss: 0.008766606152907789\n",
      "Epoch43, Batch 7000 loss: 0.006652708922653393\n",
      "Epoch44, Batch 1000 loss: 0.007061721658580199\n",
      "Epoch44, Batch 3000 loss: 0.005428758787163697\n",
      "Epoch44, Batch 5000 loss: 0.005252473955158628\n",
      "Epoch44, Batch 7000 loss: 0.005809649477983719\n",
      "Epoch45, Batch 1000 loss: 0.011360986728695453\n",
      "Epoch45, Batch 3000 loss: 0.007631431815260557\n",
      "Epoch45, Batch 5000 loss: 0.006980483104275901\n",
      "Epoch45, Batch 7000 loss: 0.008435101667575417\n",
      "Epoch46, Batch 1000 loss: 0.007036829344120323\n",
      "Epoch46, Batch 3000 loss: 0.005316970686098324\n",
      "Epoch46, Batch 5000 loss: 0.004096730140152398\n",
      "Epoch46, Batch 7000 loss: 0.004346561832109517\n",
      "Epoch47, Batch 1000 loss: 0.004581271302951078\n",
      "Epoch47, Batch 3000 loss: 0.0028006198940390093\n",
      "Epoch47, Batch 5000 loss: 0.0027012965134370734\n",
      "Epoch47, Batch 7000 loss: 0.0021763187812763774\n",
      "Epoch48, Batch 1000 loss: 0.0025333746380849353\n",
      "Epoch48, Batch 3000 loss: 0.05072285924305275\n",
      "Epoch48, Batch 5000 loss: 0.005842154524444928\n",
      "Epoch48, Batch 7000 loss: 0.004503660132146993\n",
      "Epoch49, Batch 1000 loss: 0.004274687420674\n",
      "Epoch49, Batch 3000 loss: 0.0031571573768918062\n",
      "Epoch49, Batch 5000 loss: 0.002907417693353287\n",
      "Epoch49, Batch 7000 loss: 0.002792002984305689\n",
      "Epoch50, Batch 1000 loss: 0.0032593919263148867\n",
      "Epoch50, Batch 3000 loss: 0.0026989434518123\n",
      "Epoch50, Batch 5000 loss: 0.0026744369730303474\n",
      "Epoch50, Batch 7000 loss: 0.002636123776157709\n",
      "Epoch51, Batch 1000 loss: 0.0031133308655898902\n",
      "Epoch51, Batch 3000 loss: 0.0026554832138847746\n",
      "Epoch51, Batch 5000 loss: 0.0026670458073885972\n",
      "Epoch51, Batch 7000 loss: 0.0025846572359448806\n",
      "Epoch52, Batch 1000 loss: 0.002932871043342038\n",
      "Epoch52, Batch 3000 loss: 0.002119531618989126\n",
      "Epoch52, Batch 5000 loss: 0.0020151099639469003\n",
      "Epoch52, Batch 7000 loss: 0.0019550421964071034\n",
      "Epoch53, Batch 1000 loss: 0.0022229194768103714\n",
      "Epoch53, Batch 3000 loss: 0.0018443557448944577\n",
      "Epoch53, Batch 5000 loss: 0.00208609514577432\n",
      "Epoch53, Batch 7000 loss: 0.0020278580457622954\n",
      "Epoch54, Batch 1000 loss: 0.0025709604761659888\n",
      "Epoch54, Batch 3000 loss: 0.0021277795136016883\n",
      "Epoch54, Batch 5000 loss: 0.002064840278101202\n",
      "Epoch54, Batch 7000 loss: 0.0020509484137155713\n",
      "Epoch55, Batch 1000 loss: 0.002444674018243611\n",
      "Epoch55, Batch 3000 loss: 0.0020382595504088515\n",
      "Epoch55, Batch 5000 loss: 0.002055737649345819\n",
      "Epoch55, Batch 7000 loss: 0.0020611544840529288\n",
      "Epoch56, Batch 1000 loss: 0.0024147815983720246\n",
      "Epoch56, Batch 3000 loss: 0.08025429290686611\n",
      "Epoch56, Batch 5000 loss: 0.010392603849438778\n",
      "Epoch56, Batch 7000 loss: 0.005421548654151069\n",
      "Epoch57, Batch 1000 loss: 0.0032536509848636436\n",
      "Epoch57, Batch 3000 loss: 0.002247094774024547\n",
      "Epoch57, Batch 5000 loss: 0.0021395107615228147\n",
      "Epoch57, Batch 7000 loss: 0.001705027303361799\n",
      "Epoch58, Batch 1000 loss: 0.0015522901268987595\n",
      "Epoch58, Batch 3000 loss: 0.0013409010429879223\n",
      "Epoch58, Batch 5000 loss: 0.0021613271903353657\n",
      "Epoch58, Batch 7000 loss: 0.0022601710417929706\n",
      "Epoch59, Batch 1000 loss: 0.0016425071788544157\n",
      "Epoch59, Batch 3000 loss: 0.00122778571388806\n",
      "Epoch59, Batch 5000 loss: 0.0011159542206617087\n",
      "Epoch59, Batch 7000 loss: 0.0010189936925583205\n",
      "Epoch60, Batch 1000 loss: 0.001048732192510413\n",
      "Epoch60, Batch 3000 loss: 0.000696155694367834\n",
      "Epoch60, Batch 5000 loss: 0.00048707789114894493\n",
      "Epoch60, Batch 7000 loss: 0.00035926555824917524\n",
      "Epoch61, Batch 1000 loss: 0.0003451424322510392\n",
      "Epoch61, Batch 3000 loss: 0.0002463011022387366\n",
      "Epoch61, Batch 5000 loss: 0.00022498006387119303\n",
      "Epoch61, Batch 7000 loss: 0.0002082195677858749\n",
      "Epoch62, Batch 1000 loss: 0.0002304639579261175\n",
      "Epoch62, Batch 3000 loss: 0.00018218987191760726\n",
      "Epoch62, Batch 5000 loss: 0.00017444403817664636\n",
      "Epoch62, Batch 7000 loss: 0.00016729495249123106\n",
      "Epoch63, Batch 1000 loss: 0.00019311572701253044\n",
      "Epoch63, Batch 3000 loss: 0.00015840294121085316\n",
      "Epoch63, Batch 5000 loss: 0.00015516398336002285\n",
      "Epoch63, Batch 7000 loss: 0.00015038248225494787\n",
      "Epoch64, Batch 1000 loss: 0.00017333861277551578\n",
      "Epoch64, Batch 3000 loss: 0.00014509839729690926\n",
      "Epoch64, Batch 5000 loss: 0.0001424939989903236\n",
      "Epoch64, Batch 7000 loss: 0.00014015885677103818\n",
      "Epoch65, Batch 1000 loss: 0.0001620461689217412\n",
      "Epoch65, Batch 3000 loss: 0.0001605750836606422\n",
      "Epoch65, Batch 5000 loss: 0.00013015777708584732\n",
      "Epoch65, Batch 7000 loss: 0.00013008220895692333\n",
      "Epoch66, Batch 1000 loss: 0.00015181650803904997\n",
      "Epoch66, Batch 3000 loss: 0.00012698161256993065\n",
      "Epoch66, Batch 5000 loss: 0.00012362387628937503\n",
      "Epoch66, Batch 7000 loss: 0.00012106194194511082\n",
      "Epoch67, Batch 1000 loss: 0.0001789844118141929\n",
      "Epoch67, Batch 3000 loss: 0.00011654950571598862\n",
      "Epoch67, Batch 5000 loss: 0.00011528473082912223\n",
      "Epoch67, Batch 7000 loss: 0.00011554705106724017\n",
      "Epoch68, Batch 1000 loss: 0.00013384457793524587\n",
      "Epoch68, Batch 3000 loss: 0.00011067386550040588\n",
      "Epoch68, Batch 5000 loss: 0.0001104097041334745\n",
      "Epoch68, Batch 7000 loss: 0.00012749298759264066\n",
      "Epoch69, Batch 1000 loss: 0.00012117518330111995\n",
      "Epoch69, Batch 3000 loss: 0.00010707589938631934\n",
      "Epoch69, Batch 5000 loss: 0.00010454895116022753\n",
      "Epoch69, Batch 7000 loss: 0.00010466877477314612\n",
      "Epoch70, Batch 1000 loss: 0.0001216757288829095\n",
      "Epoch70, Batch 3000 loss: 0.0001028354146454602\n",
      "Epoch70, Batch 5000 loss: 0.0001043480519676631\n",
      "Epoch70, Batch 7000 loss: 0.00010180500245136403\n",
      "Epoch71, Batch 1000 loss: 0.00011589617038726867\n",
      "Epoch71, Batch 3000 loss: 0.0033838046929513046\n",
      "Epoch71, Batch 5000 loss: 0.008836060757047244\n",
      "Epoch71, Batch 7000 loss: 0.006398669313202633\n",
      "Epoch72, Batch 1000 loss: 0.003161891044490813\n",
      "Epoch72, Batch 3000 loss: 0.0006943161226161918\n",
      "Epoch72, Batch 5000 loss: 0.0005460113525988895\n",
      "Epoch72, Batch 7000 loss: 0.0005340161684805235\n",
      "Epoch73, Batch 1000 loss: 0.0005058805884873931\n",
      "Epoch73, Batch 3000 loss: 0.00043729478104902165\n",
      "Epoch73, Batch 5000 loss: 0.00035370986419164306\n",
      "Epoch73, Batch 7000 loss: 0.00035340367948342457\n",
      "Epoch74, Batch 1000 loss: 0.0003715724966842963\n",
      "Epoch74, Batch 3000 loss: 0.00032481103946701043\n",
      "Epoch74, Batch 5000 loss: 0.00025933346414968493\n",
      "Epoch74, Batch 7000 loss: 0.00026719871523225245\n",
      "Epoch75, Batch 1000 loss: 0.00030042889603594986\n",
      "Epoch75, Batch 3000 loss: 0.0002114525585596087\n",
      "Epoch75, Batch 5000 loss: 0.00026041771148380485\n",
      "Epoch75, Batch 7000 loss: 0.0002542559819887501\n",
      "Epoch76, Batch 1000 loss: 0.00023555046489525544\n",
      "Epoch76, Batch 3000 loss: 0.00022231267379535044\n",
      "Epoch76, Batch 5000 loss: 0.00019657153531427217\n",
      "Epoch76, Batch 7000 loss: 0.1365627809502128\n",
      "Epoch77, Batch 1000 loss: 0.002425243372868983\n",
      "Epoch77, Batch 3000 loss: 0.00089523171460063\n",
      "Epoch77, Batch 5000 loss: 0.0006191302546520684\n",
      "Epoch77, Batch 7000 loss: 0.0004892519333615479\n",
      "Epoch78, Batch 1000 loss: 0.00043971435682986016\n",
      "Epoch78, Batch 3000 loss: 0.0002657177144367698\n",
      "Epoch78, Batch 5000 loss: 0.00022390498168122175\n",
      "Epoch78, Batch 7000 loss: 0.000207633899149733\n",
      "Epoch79, Batch 1000 loss: 0.0002299870705916536\n",
      "Epoch79, Batch 3000 loss: 0.00018908728678659298\n",
      "Epoch79, Batch 5000 loss: 0.0001791231664941027\n",
      "Epoch79, Batch 7000 loss: 0.00016956447369246747\n",
      "Epoch80, Batch 1000 loss: 0.0002043026864345598\n",
      "Epoch80, Batch 3000 loss: 0.00015739582338257578\n",
      "Epoch80, Batch 5000 loss: 0.00015047490467190328\n",
      "Epoch80, Batch 7000 loss: 0.00014839890015439912\n",
      "Epoch81, Batch 1000 loss: 0.0001706560126811656\n",
      "Epoch81, Batch 3000 loss: 0.00014368208530127856\n",
      "Epoch81, Batch 5000 loss: 0.00014117638486276592\n",
      "Epoch81, Batch 7000 loss: 0.00015149392790416206\n",
      "Epoch82, Batch 1000 loss: 0.00016316612418983175\n",
      "Epoch82, Batch 3000 loss: 0.00013515896495839265\n",
      "Epoch82, Batch 5000 loss: 0.0001351286254326213\n",
      "Epoch82, Batch 7000 loss: 0.00013446933219692336\n",
      "Epoch83, Batch 1000 loss: 0.00015666778915679545\n",
      "Epoch83, Batch 3000 loss: 0.0003415131062108511\n",
      "Epoch83, Batch 5000 loss: 0.00018802659633394524\n",
      "Epoch83, Batch 7000 loss: 0.00015713703907098807\n",
      "Epoch84, Batch 1000 loss: 0.00017422436341572428\n",
      "Epoch84, Batch 3000 loss: 0.0001431885347551122\n",
      "Epoch84, Batch 5000 loss: 0.00014048407515625572\n",
      "Epoch84, Batch 7000 loss: 0.00013910813999103378\n",
      "Epoch85, Batch 1000 loss: 0.0001612966943464445\n",
      "Epoch85, Batch 3000 loss: 0.00013508463885402903\n",
      "Epoch85, Batch 5000 loss: 0.00013424755277442044\n",
      "Epoch85, Batch 7000 loss: 0.00013266995740175694\n",
      "Epoch86, Batch 1000 loss: 0.00015407252078555023\n",
      "Epoch86, Batch 3000 loss: 0.0001305446636714498\n",
      "Epoch86, Batch 5000 loss: 0.00013079098163205796\n",
      "Epoch86, Batch 7000 loss: 0.00012798949220745452\n",
      "Epoch87, Batch 1000 loss: 0.0001503988910715218\n",
      "Epoch87, Batch 3000 loss: 0.00012691459241755213\n",
      "Epoch87, Batch 5000 loss: 0.00012673946155780598\n",
      "Epoch87, Batch 7000 loss: 0.00012395999502016637\n",
      "Epoch88, Batch 1000 loss: 0.00014645004129303256\n",
      "Epoch88, Batch 3000 loss: 0.00018754024634738011\n",
      "Epoch88, Batch 5000 loss: 0.00012131925111081645\n",
      "Epoch88, Batch 7000 loss: 0.0001283411403516894\n",
      "Epoch89, Batch 1000 loss: 0.0001422996558402917\n",
      "Epoch89, Batch 3000 loss: 0.000122228489128107\n",
      "Epoch89, Batch 5000 loss: 0.0001208011366813176\n",
      "Epoch89, Batch 7000 loss: 0.00012430130978035604\n",
      "Epoch90, Batch 1000 loss: 0.00013931076482846206\n",
      "Epoch90, Batch 3000 loss: 0.00011852249132321258\n",
      "Epoch90, Batch 5000 loss: 0.00011793858839443578\n",
      "Epoch90, Batch 7000 loss: 0.00011863486811140961\n",
      "Epoch91, Batch 1000 loss: 0.00013974017939437784\n",
      "Epoch91, Batch 3000 loss: 0.00011672328950721989\n",
      "Epoch91, Batch 5000 loss: 0.00011503478175808258\n",
      "Epoch91, Batch 7000 loss: 0.00011687419057378096\n",
      "Epoch92, Batch 1000 loss: 0.00013265628417524327\n",
      "Epoch92, Batch 3000 loss: 0.00011566661868532705\n",
      "Epoch92, Batch 5000 loss: 0.0001118840625086706\n",
      "Epoch92, Batch 7000 loss: 0.00011182679758444625\n",
      "Epoch93, Batch 1000 loss: 0.00013262602289814483\n",
      "Epoch93, Batch 3000 loss: 0.00011141617569476193\n",
      "Epoch93, Batch 5000 loss: 0.0001114744055615931\n",
      "Epoch93, Batch 7000 loss: 0.00010913451986246394\n",
      "Epoch94, Batch 1000 loss: 0.00012880619266383194\n",
      "Epoch94, Batch 3000 loss: 0.00010859904135463701\n",
      "Epoch94, Batch 5000 loss: 0.00010844408012470225\n",
      "Epoch94, Batch 7000 loss: 0.00010661979187029505\n",
      "Epoch95, Batch 1000 loss: 34.776950550327946\n",
      "Epoch95, Batch 3000 loss: 0.027023062767590294\n",
      "Epoch95, Batch 5000 loss: 0.013981853291757176\n",
      "Epoch95, Batch 7000 loss: 0.009231419863775712\n",
      "Epoch96, Batch 1000 loss: 0.007543426278403691\n",
      "Epoch96, Batch 3000 loss: 0.00463389175768477\n",
      "Epoch96, Batch 5000 loss: 0.003466810726108168\n",
      "Epoch96, Batch 7000 loss: 0.0028596532740117623\n",
      "Epoch97, Batch 1000 loss: 0.002444248750235151\n",
      "Epoch97, Batch 3000 loss: 0.001114032700480687\n",
      "Epoch97, Batch 5000 loss: 0.0007862056357508954\n",
      "Epoch97, Batch 7000 loss: 0.0005780862499537665\n",
      "Epoch98, Batch 1000 loss: 0.0004401146915896282\n",
      "Epoch98, Batch 3000 loss: 0.0002914331010291664\n",
      "Epoch98, Batch 5000 loss: 0.00023861200094812425\n",
      "Epoch98, Batch 7000 loss: 0.00021839002395920802\n",
      "Epoch99, Batch 1000 loss: 0.00023247716787804375\n",
      "Epoch99, Batch 3000 loss: 0.0001893294559996437\n",
      "Epoch99, Batch 5000 loss: 0.00017922978720920403\n",
      "Epoch99, Batch 7000 loss: 0.00017561938618454402\n",
      "Epoch100, Batch 1000 loss: 0.00019856654640241147\n",
      "Epoch100, Batch 3000 loss: 0.00016378096744610593\n",
      "Epoch100, Batch 5000 loss: 0.00016079874926152834\n",
      "Epoch100, Batch 7000 loss: 0.0001574335168058289\n",
      "Epoch101, Batch 1000 loss: 0.00018353650807611768\n",
      "Epoch101, Batch 3000 loss: 0.00014900417934251065\n",
      "Epoch101, Batch 5000 loss: 0.00018390649227630263\n",
      "Epoch101, Batch 7000 loss: 0.00014679998366256595\n",
      "Epoch102, Batch 1000 loss: 0.00016938285860166932\n",
      "Epoch102, Batch 3000 loss: 0.000144062492538014\n",
      "Epoch102, Batch 5000 loss: 0.00013741115255561798\n",
      "Epoch102, Batch 7000 loss: 0.00013685229530968702\n",
      "Epoch103, Batch 1000 loss: 0.00015540093694731656\n",
      "Epoch103, Batch 3000 loss: 0.0001283854683438997\n",
      "Epoch103, Batch 5000 loss: 0.000128585022145167\n",
      "Epoch103, Batch 7000 loss: 0.00012723859160466947\n",
      "Epoch104, Batch 1000 loss: 0.0001483779961568161\n",
      "Epoch104, Batch 3000 loss: 0.0001271801792647766\n",
      "Epoch104, Batch 5000 loss: 0.00012030174883293071\n",
      "Epoch104, Batch 7000 loss: 0.00012109556538419041\n",
      "Epoch105, Batch 1000 loss: 0.00013956768850242627\n",
      "Epoch105, Batch 3000 loss: 0.0001213427901132316\n",
      "Epoch105, Batch 5000 loss: 0.00011723221854596562\n",
      "Epoch105, Batch 7000 loss: 0.00011678170829452407\n",
      "Epoch106, Batch 1000 loss: 0.00013523047200944202\n",
      "Epoch106, Batch 3000 loss: 0.000155515354124517\n",
      "Epoch106, Batch 5000 loss: 0.00011477758333646072\n",
      "Epoch106, Batch 7000 loss: 0.00010949895752800781\n",
      "Epoch107, Batch 1000 loss: 0.00013052020193855015\n",
      "Epoch107, Batch 3000 loss: 0.00011198548480384086\n",
      "Epoch107, Batch 5000 loss: 0.0001100518503536105\n",
      "Epoch107, Batch 7000 loss: 0.00010865303656691495\n",
      "Epoch108, Batch 1000 loss: 0.00012680362046399698\n",
      "Epoch108, Batch 3000 loss: 0.00010369304108042606\n",
      "Epoch108, Batch 5000 loss: 0.00010916888433374379\n",
      "Epoch108, Batch 7000 loss: 0.0001067173618669368\n",
      "Epoch109, Batch 1000 loss: 0.00012332442483768176\n",
      "Epoch109, Batch 3000 loss: 0.00010341126950872571\n",
      "Epoch109, Batch 5000 loss: 0.00010117750670718902\n",
      "Epoch109, Batch 7000 loss: 0.00010194747883299834\n",
      "Epoch110, Batch 1000 loss: 0.00011828704385291701\n",
      "Epoch110, Batch 3000 loss: 9.925577777320168e-05\n",
      "Epoch110, Batch 5000 loss: 0.00010091168489484603\n",
      "Epoch110, Batch 7000 loss: 9.986023148013733e-05\n",
      "Epoch111, Batch 1000 loss: 0.00011374573237692826\n",
      "Epoch111, Batch 3000 loss: 9.620465694916475e-05\n",
      "Epoch111, Batch 5000 loss: 0.0001008728867350866\n",
      "Epoch111, Batch 7000 loss: 9.626820817452545e-05\n",
      "Epoch112, Batch 1000 loss: 0.00011513291034494723\n",
      "Epoch112, Batch 3000 loss: 9.515656118306425e-05\n",
      "Epoch112, Batch 5000 loss: 9.451126672045923e-05\n",
      "Epoch112, Batch 7000 loss: 9.557784843877941e-05\n",
      "Epoch113, Batch 1000 loss: 0.00011062162142098255\n",
      "Epoch113, Batch 3000 loss: 9.165543920750926e-05\n",
      "Epoch113, Batch 5000 loss: 9.116760430876895e-05\n",
      "Epoch113, Batch 7000 loss: 9.230600835290743e-05\n",
      "Epoch114, Batch 1000 loss: 0.00011089840209975655\n",
      "Epoch114, Batch 3000 loss: 9.090622161221613e-05\n",
      "Epoch114, Batch 5000 loss: 9.066344206106032e-05\n",
      "Epoch114, Batch 7000 loss: 8.837501479536011e-05\n",
      "Epoch115, Batch 1000 loss: 0.00010881026928596805\n",
      "Epoch115, Batch 3000 loss: 8.672322247167482e-05\n",
      "Epoch115, Batch 5000 loss: 9.08099640073595e-05\n",
      "Epoch115, Batch 7000 loss: 8.71952000863276e-05\n",
      "Epoch116, Batch 1000 loss: 0.00010911972255980578\n",
      "Epoch116, Batch 3000 loss: 8.5028788816192e-05\n",
      "Epoch116, Batch 5000 loss: 8.602523003978543e-05\n",
      "Epoch116, Batch 7000 loss: 8.638372560863273e-05\n",
      "Epoch117, Batch 1000 loss: 9.972088412441844e-05\n",
      "Epoch117, Batch 3000 loss: 8.346137519746222e-05\n",
      "Epoch117, Batch 5000 loss: 8.270923231212797e-05\n",
      "Epoch117, Batch 7000 loss: 8.234963764905249e-05\n",
      "Epoch118, Batch 1000 loss: 9.665493615727406e-05\n",
      "Epoch118, Batch 3000 loss: 8.769704715542296e-05\n",
      "Epoch118, Batch 5000 loss: 8.062460072639676e-05\n",
      "Epoch118, Batch 7000 loss: 8.03012845347329e-05\n",
      "Epoch119, Batch 1000 loss: 9.354636326646182e-05\n",
      "Epoch119, Batch 3000 loss: 7.976711017624665e-05\n",
      "Epoch119, Batch 5000 loss: 7.784401104573371e-05\n",
      "Epoch119, Batch 7000 loss: 8.609172294390271e-05\n",
      "Epoch120, Batch 1000 loss: 8.983618073189244e-05\n",
      "Epoch120, Batch 3000 loss: 7.820943576317142e-05\n",
      "Epoch120, Batch 5000 loss: 0.00045049522561725955\n",
      "Epoch120, Batch 7000 loss: 0.00023368964139925676\n",
      "Epoch121, Batch 1000 loss: 0.0002215934846658089\n",
      "Epoch121, Batch 3000 loss: 0.00016518771629692937\n",
      "Epoch121, Batch 5000 loss: 3483.805376615886\n",
      "Epoch121, Batch 7000 loss: 0.02402789664705559\n",
      "Epoch122, Batch 1000 loss: 0.022900292954831782\n",
      "Epoch122, Batch 3000 loss: 0.017990951556895153\n",
      "Epoch122, Batch 5000 loss: 0.016507806216178283\n",
      "Epoch122, Batch 7000 loss: 0.013574401223173164\n",
      "Epoch123, Batch 1000 loss: 0.01055006791182782\n",
      "Epoch123, Batch 3000 loss: 0.005722500837269089\n",
      "Epoch123, Batch 5000 loss: 0.004099353286896366\n",
      "Epoch123, Batch 7000 loss: 0.002833136345256878\n",
      "Epoch124, Batch 1000 loss: 0.0015888530342455822\n",
      "Epoch124, Batch 3000 loss: 0.0006944318688024077\n",
      "Epoch124, Batch 5000 loss: 0.00043933779634900647\n",
      "Epoch124, Batch 7000 loss: 0.0003204063863187173\n",
      "Epoch125, Batch 1000 loss: 0.00029390287088887866\n",
      "Epoch125, Batch 3000 loss: 0.00018917319104150052\n",
      "Epoch125, Batch 5000 loss: 0.00016646386655420239\n",
      "Epoch125, Batch 7000 loss: 0.00015165682276302344\n",
      "Epoch126, Batch 1000 loss: 0.00016764077945649974\n",
      "Epoch126, Batch 3000 loss: 0.00013427229414101846\n",
      "Epoch126, Batch 5000 loss: 0.00012838215835634726\n",
      "Epoch126, Batch 7000 loss: 0.00012507287072287314\n",
      "Epoch127, Batch 1000 loss: 0.00014049240111418026\n",
      "Epoch127, Batch 3000 loss: 0.00011780338562791817\n",
      "Epoch127, Batch 5000 loss: 0.00011686760707138726\n",
      "Epoch127, Batch 7000 loss: 0.00011808142133081482\n",
      "Epoch128, Batch 1000 loss: 0.00013383092814834023\n",
      "Epoch128, Batch 3000 loss: 0.00011373826974289192\n",
      "Epoch128, Batch 5000 loss: 0.00011215663762380663\n",
      "Epoch128, Batch 7000 loss: 0.00011310941346370683\n",
      "Epoch129, Batch 1000 loss: 0.0001308030046821652\n",
      "Epoch129, Batch 3000 loss: 0.00011062263984832223\n",
      "Epoch129, Batch 5000 loss: 0.00011059796893376155\n",
      "Epoch129, Batch 7000 loss: 0.00011045076948041529\n",
      "Epoch130, Batch 1000 loss: 0.00012910486108953006\n",
      "Epoch130, Batch 3000 loss: 0.00010685855017387583\n",
      "Epoch130, Batch 5000 loss: 0.00010747455325509665\n",
      "Epoch130, Batch 7000 loss: 0.00010963689224136165\n",
      "Epoch131, Batch 1000 loss: 0.0001264158093099822\n",
      "Epoch131, Batch 3000 loss: 0.00010751412659315424\n",
      "Epoch131, Batch 5000 loss: 0.00010684205515765997\n",
      "Epoch131, Batch 7000 loss: 0.00010664269628641501\n",
      "Epoch132, Batch 1000 loss: 0.00012431323310587382\n",
      "Epoch132, Batch 3000 loss: 0.00010467624157851874\n",
      "Epoch132, Batch 5000 loss: 0.00010615359495711665\n",
      "Epoch132, Batch 7000 loss: 0.00010360775962340622\n",
      "Epoch133, Batch 1000 loss: 0.00012382741329227103\n",
      "Epoch133, Batch 3000 loss: 0.00010444648633028526\n",
      "Epoch133, Batch 5000 loss: 0.00010424533775402688\n",
      "Epoch133, Batch 7000 loss: 0.00010361895448707659\n",
      "Epoch134, Batch 1000 loss: 0.00012204890831423646\n",
      "Epoch134, Batch 3000 loss: 0.00010305404999913587\n",
      "Epoch134, Batch 5000 loss: 0.0001037304042352743\n",
      "Epoch134, Batch 7000 loss: 0.00010232191070652461\n",
      "Epoch135, Batch 1000 loss: 0.00012045404570051603\n",
      "Epoch135, Batch 3000 loss: 0.00010244460969821098\n",
      "Epoch135, Batch 5000 loss: 0.0001017334038435341\n",
      "Epoch135, Batch 7000 loss: 0.00010146263618699046\n",
      "Epoch136, Batch 1000 loss: 0.00011885328563851758\n",
      "Epoch136, Batch 3000 loss: 0.00010050094775112674\n",
      "Epoch136, Batch 5000 loss: 0.0001009194157053409\n",
      "Epoch136, Batch 7000 loss: 9.897576283226859e-05\n",
      "Epoch137, Batch 1000 loss: 0.00011849158682261719\n",
      "Epoch137, Batch 3000 loss: 0.00010007363013114139\n",
      "Epoch137, Batch 5000 loss: 9.837917823070376e-05\n",
      "Epoch137, Batch 7000 loss: 9.980294416489926e-05\n",
      "Epoch138, Batch 1000 loss: 0.00011674776202903946\n",
      "Epoch138, Batch 3000 loss: 9.905544578213033e-05\n",
      "Epoch138, Batch 5000 loss: 9.746353199755652e-05\n",
      "Epoch138, Batch 7000 loss: 0.00010174892483370612\n",
      "Epoch139, Batch 1000 loss: 0.00011563103892465338\n",
      "Epoch139, Batch 3000 loss: 9.760297867705666e-05\n",
      "Epoch139, Batch 5000 loss: 9.847860844722472e-05\n",
      "Epoch139, Batch 7000 loss: 9.757921673889618e-05\n",
      "Epoch140, Batch 1000 loss: 0.00011492512054978125\n",
      "Epoch140, Batch 3000 loss: 9.741412534041165e-05\n",
      "Epoch140, Batch 5000 loss: 9.695199053071656e-05\n",
      "Epoch140, Batch 7000 loss: 9.676346578013998e-05\n",
      "Epoch141, Batch 1000 loss: 0.00011342017357053488\n",
      "Epoch141, Batch 3000 loss: 9.572961650148711e-05\n",
      "Epoch141, Batch 5000 loss: 9.862202399470032e-05\n",
      "Epoch141, Batch 7000 loss: 9.46111336358072e-05\n",
      "Epoch142, Batch 1000 loss: 0.00011305495187837974\n",
      "Epoch142, Batch 3000 loss: 9.566979797368018e-05\n",
      "Epoch142, Batch 5000 loss: 9.416828486427913e-05\n",
      "Epoch142, Batch 7000 loss: 9.531169372278345e-05\n",
      "Epoch143, Batch 1000 loss: 0.0001107291537636318\n",
      "Epoch143, Batch 3000 loss: 9.432521182237992e-05\n",
      "Epoch143, Batch 5000 loss: 9.416854709350933e-05\n",
      "Epoch143, Batch 7000 loss: 9.435671106562452e-05\n",
      "Epoch144, Batch 1000 loss: 0.00011000677552459627\n",
      "Epoch144, Batch 3000 loss: 9.322893488121575e-05\n",
      "Epoch144, Batch 5000 loss: 9.260166726057197e-05\n",
      "Epoch144, Batch 7000 loss: 9.146076023934912e-05\n",
      "Epoch145, Batch 1000 loss: 0.00010430251388968157\n",
      "Epoch145, Batch 3000 loss: 8.831411690774192e-05\n",
      "Epoch145, Batch 5000 loss: 0.00011599704818007028\n",
      "Epoch145, Batch 7000 loss: 8.702509761859444e-05\n",
      "Epoch146, Batch 1000 loss: 0.00010093247652998687\n",
      "Epoch146, Batch 3000 loss: 8.511666003814347e-05\n",
      "Epoch146, Batch 5000 loss: 8.526530261591287e-05\n",
      "Epoch146, Batch 7000 loss: 8.719752844367846e-05\n",
      "Epoch147, Batch 1000 loss: 9.91455884602672e-05\n",
      "Epoch147, Batch 3000 loss: 9.050037192319956e-05\n",
      "Epoch147, Batch 5000 loss: 8.747983223565224e-05\n",
      "Epoch147, Batch 7000 loss: 8.584155319208526e-05\n",
      "Epoch148, Batch 1000 loss: 9.964117677911755e-05\n",
      "Epoch148, Batch 3000 loss: 8.340706802544514e-05\n",
      "Epoch148, Batch 5000 loss: 8.315549716833151e-05\n",
      "Epoch148, Batch 7000 loss: 8.27387446559025e-05\n",
      "Epoch149, Batch 1000 loss: 9.706492888423082e-05\n",
      "Epoch149, Batch 3000 loss: 8.134525306782935e-05\n",
      "Epoch149, Batch 5000 loss: 8.199064031519738e-05\n",
      "Epoch149, Batch 7000 loss: 8.092855174086778e-05\n",
      "Epoch150, Batch 1000 loss: 9.456612921981822e-05\n",
      "Epoch150, Batch 3000 loss: 8.015631709748572e-05\n",
      "Epoch150, Batch 5000 loss: 8.046248937489329e-05\n",
      "Epoch150, Batch 7000 loss: 8.023278748440693e-05\n",
      "Epoch151, Batch 1000 loss: 9.575638738061989e-05\n",
      "Epoch151, Batch 3000 loss: 8.022396935305703e-05\n",
      "Epoch151, Batch 5000 loss: 7.943490813588154e-05\n",
      "Epoch151, Batch 7000 loss: 8.020009906166277e-05\n",
      "Epoch152, Batch 1000 loss: 9.366859213319913e-05\n",
      "Epoch152, Batch 3000 loss: 7.792309650564373e-05\n",
      "Epoch152, Batch 5000 loss: 7.866757317560134e-05\n",
      "Epoch152, Batch 7000 loss: 7.896710072069556e-05\n",
      "Epoch153, Batch 1000 loss: 9.099445926956482e-05\n",
      "Epoch153, Batch 3000 loss: 7.746431954901885e-05\n",
      "Epoch153, Batch 5000 loss: 7.734480140361881e-05\n",
      "Epoch153, Batch 7000 loss: 7.749813573701934e-05\n",
      "Epoch154, Batch 1000 loss: 9.717288425109567e-05\n",
      "Epoch154, Batch 3000 loss: 7.756251652291732e-05\n",
      "Epoch154, Batch 5000 loss: 7.651724656602552e-05\n",
      "Epoch154, Batch 7000 loss: 8.188305606518747e-05\n",
      "Epoch155, Batch 1000 loss: 8.955093476031263e-05\n",
      "Epoch155, Batch 3000 loss: 7.666976844679745e-05\n",
      "Epoch155, Batch 5000 loss: 7.655741874629176e-05\n",
      "Epoch155, Batch 7000 loss: 7.56819669432323e-05\n",
      "Epoch156, Batch 1000 loss: 0.00011013623119650646\n",
      "Epoch156, Batch 3000 loss: 7.984767187893055e-05\n",
      "Epoch156, Batch 5000 loss: 7.981443302779169e-05\n",
      "Epoch156, Batch 7000 loss: 7.725343482513666e-05\n",
      "Epoch157, Batch 1000 loss: 9.071304158581293e-05\n",
      "Epoch157, Batch 3000 loss: 7.585733075951406e-05\n",
      "Epoch157, Batch 5000 loss: 7.501571184282165e-05\n",
      "Epoch157, Batch 7000 loss: 8.113262931610634e-05\n",
      "Epoch158, Batch 1000 loss: 8.794061462727362e-05\n",
      "Epoch158, Batch 3000 loss: 7.421430553901841e-05\n",
      "Epoch158, Batch 5000 loss: 7.299425268020979e-05\n",
      "Epoch158, Batch 7000 loss: 7.404872420761864e-05\n",
      "Epoch159, Batch 1000 loss: 8.562131807864743e-05\n",
      "Epoch159, Batch 3000 loss: 7.32265910939337e-05\n",
      "Epoch159, Batch 5000 loss: 7.395304459793448e-05\n",
      "Epoch159, Batch 7000 loss: 7.232747878555305e-05\n",
      "Epoch160, Batch 1000 loss: 8.57606486678478e-05\n",
      "Epoch160, Batch 3000 loss: 7.214684610174345e-05\n",
      "Epoch160, Batch 5000 loss: 7.260641050200911e-05\n",
      "Epoch160, Batch 7000 loss: 7.334686761222809e-05\n",
      "Epoch161, Batch 1000 loss: 8.47014439090773e-05\n",
      "Epoch161, Batch 3000 loss: 7.117978885873665e-05\n",
      "Epoch161, Batch 5000 loss: 7.139654086441362e-05\n",
      "Epoch161, Batch 7000 loss: 7.181626003679428e-05\n",
      "Epoch162, Batch 1000 loss: 8.567468701310626e-05\n",
      "Epoch162, Batch 3000 loss: 7.123537161120287e-05\n",
      "Epoch162, Batch 5000 loss: 7.085842695983308e-05\n",
      "Epoch162, Batch 7000 loss: 7.118140775302474e-05\n",
      "Epoch163, Batch 1000 loss: 8.312202572023696e-05\n",
      "Epoch163, Batch 3000 loss: 7.059836592331195e-05\n",
      "Epoch163, Batch 5000 loss: 7.04981385230486e-05\n",
      "Epoch163, Batch 7000 loss: 7.029504331632315e-05\n",
      "Epoch164, Batch 1000 loss: 8.214958120685928e-05\n",
      "Epoch164, Batch 3000 loss: 7.159227802444701e-05\n",
      "Epoch164, Batch 5000 loss: 6.982557528751316e-05\n",
      "Epoch164, Batch 7000 loss: 6.96116436499384e-05\n",
      "Epoch165, Batch 1000 loss: 8.200656657172748e-05\n",
      "Epoch165, Batch 3000 loss: 6.901307304452511e-05\n",
      "Epoch165, Batch 5000 loss: 6.927519726558278e-05\n",
      "Epoch165, Batch 7000 loss: 0.00718195199790751\n",
      "Epoch166, Batch 1000 loss: 0.002759637277229538\n",
      "Epoch166, Batch 3000 loss: 0.001652020063389437\n",
      "Epoch166, Batch 5000 loss: 0.001281600924364971\n",
      "Epoch166, Batch 7000 loss: 0.000995731855588004\n",
      "Epoch167, Batch 1000 loss: 0.0008585209559023963\n",
      "Epoch167, Batch 3000 loss: 0.0005044305303555512\n",
      "Epoch167, Batch 5000 loss: 0.0003152166581453018\n",
      "Epoch167, Batch 7000 loss: 0.00021575951363917432\n",
      "Epoch168, Batch 1000 loss: 0.00020160796970353594\n",
      "Epoch168, Batch 3000 loss: 0.00014992631571752752\n",
      "Epoch168, Batch 5000 loss: 0.00013781064131179426\n",
      "Epoch168, Batch 7000 loss: 0.00013115632762875093\n",
      "Epoch169, Batch 1000 loss: 0.00014738172359796923\n",
      "Epoch169, Batch 3000 loss: 0.00011909006810301939\n",
      "Epoch169, Batch 5000 loss: 0.00011764178206686614\n",
      "Epoch169, Batch 7000 loss: 0.00011377041640219823\n",
      "Epoch170, Batch 1000 loss: 0.00013106123373754784\n",
      "Epoch170, Batch 3000 loss: 0.0001094755493704116\n",
      "Epoch170, Batch 5000 loss: 0.00010791944253111641\n",
      "Epoch170, Batch 7000 loss: 0.00010701875012298272\n",
      "Epoch171, Batch 1000 loss: 0.0001244488996482037\n",
      "Epoch171, Batch 3000 loss: 0.0001041446765726419\n",
      "Epoch171, Batch 5000 loss: 0.00010424171622370623\n",
      "Epoch171, Batch 7000 loss: 0.0001029420954693713\n",
      "Epoch172, Batch 1000 loss: 0.00011967078750142868\n",
      "Epoch172, Batch 3000 loss: 0.00010122392259776289\n",
      "Epoch172, Batch 5000 loss: 0.00010073591591090391\n",
      "Epoch172, Batch 7000 loss: 0.00010032625775174722\n",
      "Epoch173, Batch 1000 loss: 0.00011642753003528883\n",
      "Epoch173, Batch 3000 loss: 0.00010002067535875408\n",
      "Epoch173, Batch 5000 loss: 9.883226471703161e-05\n",
      "Epoch173, Batch 7000 loss: 9.848764550518178e-05\n",
      "Epoch174, Batch 1000 loss: 0.00011542216826768153\n",
      "Epoch174, Batch 3000 loss: 9.836994481829602e-05\n",
      "Epoch174, Batch 5000 loss: 9.720699020366635e-05\n",
      "Epoch174, Batch 7000 loss: 9.661458426460045e-05\n",
      "Epoch175, Batch 1000 loss: 0.00011384597252076924\n",
      "Epoch175, Batch 3000 loss: 9.640565537727335e-05\n",
      "Epoch175, Batch 5000 loss: 9.662243191026256e-05\n",
      "Epoch175, Batch 7000 loss: 9.585540154964512e-05\n",
      "Epoch176, Batch 1000 loss: 0.00011264118075048497\n",
      "Epoch176, Batch 3000 loss: 9.523905971694986e-05\n",
      "Epoch176, Batch 5000 loss: 9.682785264416863e-05\n",
      "Epoch176, Batch 7000 loss: 9.448620857056784e-05\n",
      "Epoch177, Batch 1000 loss: 0.00011157695122747364\n",
      "Epoch177, Batch 3000 loss: 9.471507097865243e-05\n",
      "Epoch177, Batch 5000 loss: 9.416838493326262e-05\n",
      "Epoch177, Batch 7000 loss: 9.480377953180806e-05\n",
      "Epoch178, Batch 1000 loss: 0.00011071445612899744\n",
      "Epoch178, Batch 3000 loss: 9.41507540617621e-05\n",
      "Epoch178, Batch 5000 loss: 9.288817266097702e-05\n",
      "Epoch178, Batch 7000 loss: 9.365997879222469e-05\n",
      "Epoch179, Batch 1000 loss: 0.00010961888051312332\n",
      "Epoch179, Batch 3000 loss: 9.272070015227572e-05\n",
      "Epoch179, Batch 5000 loss: 9.269535089551305e-05\n",
      "Epoch179, Batch 7000 loss: 9.256294058507913e-05\n",
      "Epoch180, Batch 1000 loss: 0.00010944475070373976\n",
      "Epoch180, Batch 3000 loss: 9.239157827490718e-05\n",
      "Epoch180, Batch 5000 loss: 9.18664301283901e-05\n",
      "Epoch180, Batch 7000 loss: 9.204556647832642e-05\n",
      "Epoch181, Batch 1000 loss: 0.00010978438873893727\n",
      "Epoch181, Batch 3000 loss: 9.176504353302048e-05\n",
      "Epoch181, Batch 5000 loss: 9.149605205962646e-05\n",
      "Epoch181, Batch 7000 loss: 9.154529811380405e-05\n",
      "Epoch182, Batch 1000 loss: 0.00010716942043286913\n",
      "Epoch182, Batch 3000 loss: 9.095375665759977e-05\n",
      "Epoch182, Batch 5000 loss: 9.135560266614513e-05\n",
      "Epoch182, Batch 7000 loss: 9.072060619763018e-05\n",
      "Epoch183, Batch 1000 loss: 0.00010652100299562257\n",
      "Epoch183, Batch 3000 loss: 8.99500913803374e-05\n",
      "Epoch183, Batch 5000 loss: 8.99216656758809e-05\n",
      "Epoch183, Batch 7000 loss: 8.957230812064312e-05\n",
      "Epoch184, Batch 1000 loss: 0.00010651203304786995\n",
      "Epoch184, Batch 3000 loss: 8.97573544365263e-05\n",
      "Epoch184, Batch 5000 loss: 8.965923244842782e-05\n",
      "Epoch184, Batch 7000 loss: 8.942897902465107e-05\n",
      "Epoch185, Batch 1000 loss: 0.00010588583406428569\n",
      "Epoch185, Batch 3000 loss: 8.935325937423415e-05\n",
      "Epoch185, Batch 5000 loss: 8.857513967069241e-05\n",
      "Epoch185, Batch 7000 loss: 8.901173735103795e-05\n",
      "Epoch186, Batch 1000 loss: 0.00010445029093699562\n",
      "Epoch186, Batch 3000 loss: 8.840358518167891e-05\n",
      "Epoch186, Batch 5000 loss: 8.835461112792187e-05\n",
      "Epoch186, Batch 7000 loss: 8.872226810958024e-05\n",
      "Epoch187, Batch 1000 loss: 0.00010365875709017445\n",
      "Epoch187, Batch 3000 loss: 8.819983331823102e-05\n",
      "Epoch187, Batch 5000 loss: 8.796273277010808e-05\n",
      "Epoch187, Batch 7000 loss: 8.806655491760981e-05\n",
      "Epoch188, Batch 1000 loss: 0.00010251574070310689\n",
      "Epoch188, Batch 3000 loss: 8.780064467581792e-05\n",
      "Epoch188, Batch 5000 loss: 8.728793060492066e-05\n",
      "Epoch188, Batch 7000 loss: 8.735490840014343e-05\n",
      "Epoch189, Batch 1000 loss: 0.00010277332253660013\n",
      "Epoch189, Batch 3000 loss: 8.700212607171769e-05\n",
      "Epoch189, Batch 5000 loss: 8.656440038972937e-05\n",
      "Epoch189, Batch 7000 loss: 8.707694667154494e-05\n",
      "Epoch190, Batch 1000 loss: 0.00010181286316432762\n",
      "Epoch190, Batch 3000 loss: 8.720069544125629e-05\n",
      "Epoch190, Batch 5000 loss: 8.58394460242103e-05\n",
      "Epoch190, Batch 7000 loss: 8.618226712994498e-05\n",
      "Epoch191, Batch 1000 loss: 0.00010164714385376872\n",
      "Epoch191, Batch 3000 loss: 8.617163940293283e-05\n",
      "Epoch191, Batch 5000 loss: 8.57024673472413e-05\n",
      "Epoch191, Batch 7000 loss: 8.56097137332888e-05\n",
      "Epoch192, Batch 1000 loss: 0.00010035019251462964\n",
      "Epoch192, Batch 3000 loss: 8.561754028270584e-05\n",
      "Epoch192, Batch 5000 loss: 8.599668397976266e-05\n",
      "Epoch192, Batch 7000 loss: 8.549074270875985e-05\n",
      "Epoch193, Batch 1000 loss: 0.0001003817231464648\n",
      "Epoch193, Batch 3000 loss: 8.542043733880752e-05\n",
      "Epoch193, Batch 5000 loss: 8.468529357255264e-05\n",
      "Epoch193, Batch 7000 loss: 8.507217976384974e-05\n",
      "Epoch194, Batch 1000 loss: 9.987186315412603e-05\n",
      "Epoch194, Batch 3000 loss: 8.522526258258497e-05\n",
      "Epoch194, Batch 5000 loss: 8.465493003848345e-05\n",
      "Epoch194, Batch 7000 loss: 8.453652850603949e-05\n",
      "Epoch195, Batch 1000 loss: 9.913947990985636e-05\n",
      "Epoch195, Batch 3000 loss: 8.450706439859285e-05\n",
      "Epoch195, Batch 5000 loss: 8.463656926662695e-05\n",
      "Epoch195, Batch 7000 loss: 8.429130206495664e-05\n",
      "Epoch196, Batch 1000 loss: 9.857015749498312e-05\n",
      "Epoch196, Batch 3000 loss: 8.413245431237899e-05\n",
      "Epoch196, Batch 5000 loss: 8.427742525516725e-05\n",
      "Epoch196, Batch 7000 loss: 8.322939265717716e-05\n",
      "Epoch197, Batch 1000 loss: 9.838284884313629e-05\n",
      "Epoch197, Batch 3000 loss: 8.363927030048396e-05\n",
      "Epoch197, Batch 5000 loss: 8.357984031728983e-05\n",
      "Epoch197, Batch 7000 loss: 8.324587338434055e-05\n",
      "Epoch198, Batch 1000 loss: 9.831922012131026e-05\n",
      "Epoch198, Batch 3000 loss: 8.327724189216648e-05\n",
      "Epoch198, Batch 5000 loss: 8.304611593746486e-05\n",
      "Epoch198, Batch 7000 loss: 8.337438343749618e-05\n",
      "Epoch199, Batch 1000 loss: 9.72003495367054e-05\n",
      "Epoch199, Batch 3000 loss: 8.282328093414242e-05\n",
      "Epoch199, Batch 5000 loss: 8.31275489399596e-05\n",
      "Epoch199, Batch 7000 loss: 8.245984230317292e-05\n",
      "Epoch200, Batch 1000 loss: 9.744056236926558e-05\n",
      "Epoch200, Batch 3000 loss: 8.225480371564826e-05\n",
      "Epoch200, Batch 5000 loss: 8.263821730899007e-05\n",
      "Epoch200, Batch 7000 loss: 8.252610884167736e-05\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "autoencoder = MarketAutoencoder()\n",
    "autoencoder.train(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a3e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01688612 0.00883604 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.99530694 0.98107173]\n",
      "[-4.60517019 -4.60517019 -4.60517019 -4.60517019 -4.60517019 -4.60517019\n",
      " -4.60517019 -3.61614515 -3.97198325  1.          1.          1.\n",
      "  1.          1.          1.          1.          0.99061389  0.96214346]\n",
      "---------------------\n",
      "tensor([-0.3207, -0.4160, -0.3349], dtype=torch.float64,\n",
      "       grad_fn=<LeakyReluBackward0>)\n",
      "---------------------\n",
      "tensor([-4.6070, -4.6024, -4.6038, -4.6132, -4.6322, -4.1272, -3.9853, -3.9871,\n",
      "        -4.1143,  1.0000,  1.0001,  1.0000,  1.0004,  0.9996,  0.9774,  0.9508,\n",
      "         0.9231,  0.8947], dtype=torch.float64, grad_fn=<LeakyReluBackward0>)\n",
      "tensor([-1.8365e-05,  2.7631e-05,  1.3934e-05, -7.9763e-05, -2.6652e-04,\n",
      "         6.1286e-03,  8.5860e-03,  8.5526e-03,  6.3376e-03,  1.0000e+00,\n",
      "         1.0000e+00,  9.9999e-01,  1.0002e+00,  9.9978e-01,  9.8872e-01,\n",
      "         9.7542e-01,  9.6153e-01,  9.4736e-01], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "example_path = paths[500]\n",
    "t = 1000\n",
    "Swaptions = [example_path.Swaptions[i][t] for i in range(1,10)]\n",
    "Q_s = [example_path.Q_s[i][t] for i in range(1,10)]\n",
    "sample = np.concat([Swaptions,Q_s])\n",
    "print(sample)\n",
    "autoencoder.preprocess(sample)\n",
    "print(sample)\n",
    "print(\"---------------------\")\n",
    "k = autoencoder.encoder(th.from_numpy(sample))\n",
    "print(k)\n",
    "print(\"---------------------\")\n",
    "recovered = autoencoder.decoder(k)\n",
    "print(recovered)\n",
    "print(autoencoder.deprocess(recovered.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cabcacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"autoencoderT\",\"wb\") as fp:\n",
    "    pickle.dump(autoencoder,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
