{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ef1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osc16\\miniconda3\\envs\\d2d\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import gymnasium as gym\n",
    "from typing import Callable\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "import torch as th\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Import Our environment\n",
    "from dev_env import tradingEng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bd6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Paths\n",
    "with open(\"1.6kRunDemo.pkl\",\"rb\") as fp:\n",
    "    paths = pickle.load(fp)\n",
    "\n",
    "paths1 = paths[0:300]\n",
    "paths2 = paths[300:600]\n",
    "paths3 = paths[600:900]\n",
    "paths4 = paths[900:1200]\n",
    "del(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121d8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LR schedule\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got here?\n",
      "Using cpu device\n",
      "Number 2\n",
      "Last Step\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 652          |\n",
      "|    ep_rew_mean          | 227          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1202         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034208386 |\n",
      "|    clip_fraction        | 0.00281      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -25.8        |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.000478     |\n",
      "|    loss                 | 3.88         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000844    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 653          |\n",
      "|    ep_rew_mean          | 229          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 437          |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031343147 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -25.8        |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.000454     |\n",
      "|    loss                 | 5.99         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.18         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 652         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1102        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011865772 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.8       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00043     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 652         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008250199 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.8       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.000406    |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 3.44e-05    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.89        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 653        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1075       |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 1115       |\n",
      "|    total_timesteps      | 1200000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09710799 |\n",
      "|    clip_fraction        | 0.0939     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.9      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.000382   |\n",
      "|    loss                 | 3.36       |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | 0.00695    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 3.67       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 652         |\n",
      "|    ep_rew_mean          | 250         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1057        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1361        |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005820516 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.9       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.000358    |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 652         |\n",
      "|    ep_rew_mean          | 259         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1068        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008464126 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26         |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.000334    |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.000225   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.43        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Def Env\n",
    "def start_and_release(set, action = 'small-More-Trust', obs = 'big'):\n",
    "    ret = tradingEng(set, action = action, obs = obs)\n",
    "    del(set)\n",
    "    return ret\n",
    "\n",
    "envs = VecMonitor(SubprocVecEnv([\n",
    "    lambda: start_and_release(paths1,action = 'big',obs = 'big'),\n",
    "    lambda: start_and_release(paths2,action = 'big',obs = 'big'),\n",
    "    lambda: start_and_release(paths3,action = 'big',obs = 'big'),\n",
    "    lambda: start_and_release(paths4,action = 'big',obs = 'big'), #4\n",
    "], start_method='spawn'))\n",
    "\n",
    "print(\"Got here?\")\n",
    "\n",
    "# Instantiate the agent\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
    "                     net_arch=dict(pi=[512,512,256,128,64,64,64,64,36,18], vf=[512,512,256,128,64,64,64,64,36,18], optimizers_class = th.optim.Adam, log_std_init = False, ortho_init = False))\n",
    "model = PPO(\"MlpPolicy\", envs, batch_size = 4800, learning_rate=linear_schedule(5e-4), policy_kwargs=policy_kwargs, n_steps=1200*5, normalize_advantage=True, vf_coef = 0.9, gamma = 0.9,ent_coef=0.01, verbose = 1)\n",
    "\n",
    "print(\"Number 2\")\n",
    "#model = PPO.load(\"PPOBig\")\n",
    "#model.set_env(envs)\n",
    "#model.learning_rate = linear_schedule(1e-4)\n",
    "#model.batch_size = 2400\n",
    "#model.ent_coef = 0.005\n",
    "#model.ent_coef = 0\n",
    "\n",
    "print(\"Last Step\")\n",
    "model.learn(total_timesteps=int(5e6), log_interval=10)\n",
    "# Save the agent\n",
    "model.save(\"PPOBig2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff7a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99977158  0.05536838 -0.56841282]]\n",
      "0.005196713067477058\n",
      "0.030745992173113156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(env._get_obs())\n",
    "path = paths[800]\n",
    "lambdax = path.lambdas[25]\n",
    "r = path.r[25]\n",
    "t = path.t_s[25]\n",
    "print(lambdax)\n",
    "print(r)\n",
    "\n",
    "#model.predict(observation=np.asmatrix([lambdax,r,t]),state=None, deterministic=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
